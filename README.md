![LOGO]()

<b>R1-Onevisionï¼šAn Open-Source Multimodal Large Language Model Capable of Deep Reasoning. </b>

<a href="https://huggingface.co/datasets/Fancy-MLLM/R1-onevision">ğŸ¤— HF Dataset</a> â€¢
<a href="https://huggingface.co/datasets/Fancy-MLLM/R1-OneVision-Bench">ğŸ¤— Reasoning Benchmark</a> â€¢
<a href="https://huggingface.co/Fancy-MLLM/R1-OneVision-7B">ğŸ¤— Model weights</a> â€¢
<a href="https://huggingface.co/spaces/Fancy-MLLM/R1-OneVision">ğŸ¤— Demo</a> â€¢
<a href="https://yangyi-vai.notion.site/r1-onevision?pvs=4">ğŸ“ Report</a>
</div>

**R1-OneVision** is a versatile **multimodal reasoning large model**, designed to tackle complex visual reasoning tasks. It seamlessly integrates visual and textual data to offer precise interpretations of multimodal information, excelling in areas such as mathematics, science, deep image understanding, and logical reasoning. With its robust ability to perform multimodal reasoning, **R1-OneVision emerges as a powerful AI assistant capable of addressing a wide range of problem-solving challenges across different domains**.

![DEMO](asset/demo.jpeg)

## Roadmap for R1-V
> We are building a general framework 
>
> Welcome Ideas and Contribution. Stay tuned!

## ğŸ†• News

> We have presented a  ğŸ”¥ğŸ”¥ğŸ”¥


- **[2025-02-12]**  We have released the first verson of [dataset]([https://github.com/kge-sun/mm-math](https://huggingface.co/datasets/Fancy-MLLM/R1-onevision)), [hf models](https://huggingface.co/Fancy-MLLM/R1-OneVision-7B) and [reasoning benchmark](https://huggingface.co/datasets/Fancy-MLLM/R1-OneVision-Bench). For more details, please check our blog! ğŸ”¥ğŸ”¥ğŸ”¥

## ğŸ“Š Datasets, Models

### Evaluation Results
